{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\"\"\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-15T02:14:29.439743Z","iopub.execute_input":"2022-01-15T02:14:29.440031Z","iopub.status.idle":"2022-01-15T02:14:29.444979Z","shell.execute_reply.started":"2022-01-15T02:14:29.44Z","shell.execute_reply":"2022-01-15T02:14:29.444277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-01-15T02:14:29.752432Z","iopub.execute_input":"2022-01-15T02:14:29.752642Z","iopub.status.idle":"2022-01-15T02:14:29.756922Z","shell.execute_reply.started":"2022-01-15T02:14:29.752619Z","shell.execute_reply":"2022-01-15T02:14:29.756071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')\nprint(dataframe.shape)\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:14:30.108284Z","iopub.execute_input":"2022-01-15T02:14:30.108495Z","iopub.status.idle":"2022-01-15T02:14:35.2263Z","shell.execute_reply.started":"2022-01-15T02:14:30.108472Z","shell.execute_reply":"2022-01-15T02:14:35.225506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.emotion.unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:14:35.228296Z","iopub.execute_input":"2022-01-15T02:14:35.228523Z","iopub.status.idle":"2022-01-15T02:14:35.239008Z","shell.execute_reply.started":"2022-01-15T02:14:35.228497Z","shell.execute_reply":"2022-01-15T02:14:35.238043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_mapping = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:14:35.240573Z","iopub.execute_input":"2022-01-15T02:14:35.241136Z","iopub.status.idle":"2022-01-15T02:14:35.248719Z","shell.execute_reply.started":"2022-01-15T02:14:35.241097Z","shell.execute_reply":"2022-01-15T02:14:35.247657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.emotion.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:14:35.250883Z","iopub.execute_input":"2022-01-15T02:14:35.251234Z","iopub.status.idle":"2022-01-15T02:14:35.263827Z","shell.execute_reply.started":"2022-01-15T02:14:35.251192Z","shell.execute_reply":"2022-01-15T02:14:35.262489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(dataframe.emotion,bins=7)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:14:35.266057Z","iopub.execute_input":"2022-01-15T02:14:35.266398Z","iopub.status.idle":"2022-01-15T02:14:35.440845Z","shell.execute_reply.started":"2022-01-15T02:14:35.266357Z","shell.execute_reply":"2022-01-15T02:14:35.440239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Changing the size to make it equal.. ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nSIZE=48\ndef augment_pixels(string_grayscale):\n    image = np.array(string_grayscale.split(' ')).reshape(SIZE, SIZE).astype('float32')\n    image = tf.image.random_flip_left_right(image.reshape(SIZE,SIZE,1))# Pad image size\n    image = tf.image.resize_with_crop_or_pad(image, SIZE + 12, SIZE + 12) # Random crop back to the original size\n    image = tf.image.random_crop(image, size=[SIZE, SIZE, 1])\n    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n    image = tf.clip_by_value(image, 0, 255)\n    augmented = image.numpy().reshape(SIZE,SIZE)\n    str_augmented = ' '.join(augmented.reshape(SIZE*SIZE).astype('int').astype(str))\n    return str_augmented\n\nnumber_of_samples = dataframe.emotion.value_counts()\ndifference_between_samples = number_of_samples[number_of_samples.idxmax()] - number_of_samples\nfor emotion_id,diff in difference_between_samples.iteritems():\n    sampled = dataframe.query(\"emotion==@emotion_id\").sample(diff, replace=True)\n    sampled['pixels'] = sampled.pixels.apply(augment_pixels)\n    dataframe = pd.concat([dataframe, sampled])\n    print(emotion_id, diff)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:14:35.44249Z","iopub.execute_input":"2022-01-15T02:14:35.442738Z","iopub.status.idle":"2022-01-15T02:18:36.624528Z","shell.execute_reply.started":"2022-01-15T02:14:35.442706Z","shell.execute_reply":"2022-01-15T02:18:36.623732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.Usage.unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:18:36.625795Z","iopub.execute_input":"2022-01-15T02:18:36.626243Z","iopub.status.idle":"2022-01-15T02:18:36.637262Z","shell.execute_reply.started":"2022-01-15T02:18:36.626205Z","shell.execute_reply":"2022-01-15T02:18:36.636538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check again to see if dataset size is similar across emotions.\nplt.hist(dataframe.emotion,bins=7)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:18:36.639215Z","iopub.execute_input":"2022-01-15T02:18:36.639554Z","iopub.status.idle":"2022-01-15T02:18:36.772708Z","shell.execute_reply.started":"2022-01-15T02:18:36.639517Z","shell.execute_reply":"2022-01-15T02:18:36.772135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(1)\n\n\nfor label in range(7):\n    for j in range(3):\n        px = dataframe[dataframe.emotion==label].pixels.iloc[j]\n        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n        ax = plt.subplot(3,3,j+1)\n        ax.imshow(px)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(emotion_mapping[label])\n        plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:18:36.773766Z","iopub.execute_input":"2022-01-15T02:18:36.77402Z","iopub.status.idle":"2022-01-15T02:18:38.277904Z","shell.execute_reply.started":"2022-01-15T02:18:36.773987Z","shell.execute_reply":"2022-01-15T02:18:38.277292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INTERESTED_LABELS = [0, 1, 2, 3, 4, 5, 6]","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:18:38.279106Z","iopub.execute_input":"2022-01-15T02:18:38.279385Z","iopub.status.idle":"2022-01-15T02:18:38.284846Z","shell.execute_reply.started":"2022-01-15T02:18:38.279349Z","shell.execute_reply":"2022-01-15T02:18:38.283547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = dataframe[dataframe.emotion.isin(INTERESTED_LABELS)]\ndataframe.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:18:38.286494Z","iopub.execute_input":"2022-01-15T02:18:38.286947Z","iopub.status.idle":"2022-01-15T02:18:38.303556Z","shell.execute_reply.started":"2022-01-15T02:18:38.286909Z","shell.execute_reply":"2022-01-15T02:18:38.302871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing for neural network.`","metadata":{}},{"cell_type":"code","source":"img_array = dataframe.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))\nimg_array = np.stack(img_array, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:18:38.305135Z","iopub.execute_input":"2022-01-15T02:18:38.305417Z","iopub.status.idle":"2022-01-15T02:20:42.990697Z","shell.execute_reply.started":"2022-01-15T02:18:38.305384Z","shell.execute_reply":"2022-01-15T02:20:42.989866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:42.992176Z","iopub.execute_input":"2022-01-15T02:20:42.992453Z","iopub.status.idle":"2022-01-15T02:20:43.001691Z","shell.execute_reply.started":"2022-01-15T02:20:42.99242Z","shell.execute_reply":"2022-01-15T02:20:43.000831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nle = LabelEncoder()\nimg_labels = le.fit_transform(dataframe.emotion)\nimg_labels = to_categorical(img_labels)\nimg_labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:43.003005Z","iopub.execute_input":"2022-01-15T02:20:43.003308Z","iopub.status.idle":"2022-01-15T02:20:43.228369Z","shell.execute_reply.started":"2022-01-15T02:20:43.003272Z","shell.execute_reply":"2022-01-15T02:20:43.227606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the data into training and testing set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(img_array, img_labels,\n                                                    shuffle=True, stratify=img_labels,\n                                                    test_size=0.1, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:43.231571Z","iopub.execute_input":"2022-01-15T02:20:43.231855Z","iopub.status.idle":"2022-01-15T02:20:44.065219Z","shell.execute_reply.started":"2022-01-15T02:20:43.23182Z","shell.execute_reply":"2022-01-15T02:20:44.064417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_width = X_train.shape[1]\nimg_height = X_train.shape[2]\nimg_depth = X_train.shape[3]\nnum_classes = y_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.066956Z","iopub.execute_input":"2022-01-15T02:20:44.06725Z","iopub.status.idle":"2022-01-15T02:20:44.072421Z","shell.execute_reply.started":"2022-01-15T02:20:44.067214Z","shell.execute_reply":"2022-01-15T02:20:44.071634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.dtype,X_valid.dtype","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.074255Z","iopub.execute_input":"2022-01-15T02:20:44.074531Z","iopub.status.idle":"2022-01-15T02:20:44.085002Z","shell.execute_reply.started":"2022-01-15T02:20:44.074497Z","shell.execute_reply":"2022-01-15T02:20:44.084102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing results, as neural networks are very sensitive to unnormalized data.\nX_train = X_train / 255.\nX_valid = X_valid / 255.","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.0864Z","iopub.execute_input":"2022-01-15T02:20:44.086716Z","iopub.status.idle":"2022-01-15T02:20:44.256451Z","shell.execute_reply.started":"2022-01-15T02:20:44.086679Z","shell.execute_reply":"2022-01-15T02:20:44.255661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\ndef build_net():\n\n    net = Sequential()\n\n    net.add(Conv2D(64,(5,5),input_shape=(img_width, img_height, img_depth),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    net.add(Conv2D(64,(5,5),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    \n    net.add(MaxPooling2D(pool_size=(2,2)))\n    net.add(Dropout(0.4))\n\n    net.add(Conv2D(128,(3,3),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    net.add(Conv2D(128,(3,3),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    \n    net.add(MaxPooling2D(pool_size=(2,2)))\n    net.add(Dropout(0.4))\n\n    net.add(Conv2D(256,(3,3),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    net.add(Conv2D(256,(3,3),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    \n    net.add(MaxPooling2D(pool_size=(2,2)))\n    net.add(Dropout(0.5))\n    \n    net.add(Conv2D(512,(3,3),activation='elu',padding='same',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    net.add(MaxPooling2D(pool_size=(2,2)))\n    net.add(Dropout(0.5))\n\n    net.add(Flatten())\n        \n    net.add(Dense(128,activation='elu',kernel_initializer=\"he_normal\"))\n    net.add(BatchNormalization())\n    \n    net.add(Dropout(0.6))\n    \n    net.add(Dense(num_classes,activation='softmax',kernel_initializer=\"he_normal\"))\n    \n    net.compile(\n        loss='categorical_crossentropy',\n        optimizer=\"Adam\",\n        metrics=['accuracy']\n    )\n    \n    net.summary()\n    \n    return net","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.258048Z","iopub.execute_input":"2022-01-15T02:20:44.258469Z","iopub.status.idle":"2022-01-15T02:20:44.276213Z","shell.execute_reply.started":"2022-01-15T02:20:44.258433Z","shell.execute_reply":"2022-01-15T02:20:44.275362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.277505Z","iopub.execute_input":"2022-01-15T02:20:44.27782Z","iopub.status.idle":"2022-01-15T02:20:44.288799Z","shell.execute_reply.started":"2022-01-15T02:20:44.277781Z","shell.execute_reply":"2022-01-15T02:20:44.288072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As the data in hand is less as compared to the task so ImageDataGenerator is good to go.\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n)\ntrain_datagen.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.290723Z","iopub.execute_input":"2022-01-15T02:20:44.29137Z","iopub.status.idle":"2022-01-15T02:20:44.401497Z","shell.execute_reply.started":"2022-01-15T02:20:44.291332Z","shell.execute_reply":"2022-01-15T02:20:44.400927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = build_net() \n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.402797Z","iopub.execute_input":"2022-01-15T02:20:44.40305Z","iopub.status.idle":"2022-01-15T02:20:44.917007Z","shell.execute_reply.started":"2022-01-15T02:20:44.403018Z","shell.execute_reply":"2022-01-15T02:20:44.916359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32 #batch size of 32 performs the best.\nepochs = 150\nhistory = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size), validation_data=(X_valid, y_valid),steps_per_epoch=len(X_train) / batch_size,\n                              epochs=epochs,\n                              callbacks=callbacks,use_multiprocessing=True\n)\nmodel.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-15T02:20:44.920835Z","iopub.execute_input":"2022-01-15T02:20:44.921033Z","iopub.status.idle":"2022-01-15T03:49:51.575928Z","shell.execute_reply.started":"2022-01-15T02:20:44.921009Z","shell.execute_reply":"2022-01-15T03:49:51.574779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot \nsns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history_dcnn.png')\npyplot.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-15T03:50:18.133039Z","iopub.execute_input":"2022-01-15T03:50:18.133614Z","iopub.status.idle":"2022-01-15T03:50:19.486872Z","shell.execute_reply.started":"2022-01-15T03:50:18.13357Z","shell.execute_reply":"2022-01-15T03:50:19.486103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scikitplot\nfrom sklearn.metrics import classification_report\nyhat_valid = model.predict_classes(X_valid)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(y_valid, axis=1), yhat_valid, figsize=(7,7))\npyplot.savefig(\"confusion_matrix_dcnn.png\")\n","metadata":{"execution":{"iopub.status.busy":"2022-01-15T03:50:26.080351Z","iopub.execute_input":"2022-01-15T03:50:26.080629Z","iopub.status.idle":"2022-01-15T03:50:28.054544Z","shell.execute_reply.started":"2022-01-15T03:50:26.080601Z","shell.execute_reply":"2022-01-15T03:50:28.053841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}